{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saxenaya/miniconda3/envs/robot_commands/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import IterableDataset, Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    logging,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeDataset(Dataset):\n",
    "    def __init__(self, data_dir, tokenizer, prompt):\n",
    "        self.data_dir = data_dir\n",
    "        self.example_folders = os.listdir(self.data_dir)\n",
    "\n",
    "        self.data = []\n",
    "\n",
    "        # Number of prompts for in each folder\n",
    "        prompt_lengths = []\n",
    "        self.total_length = 0\n",
    "\n",
    "        for d in self.example_folders:\n",
    "            prompts_dir = os.path.join(self.data_dir, d, \"prompts.txt\")\n",
    "\n",
    "            with open(prompts_dir, 'r') as f:\n",
    "                prompts = f.read()\n",
    "\n",
    "            prompt_length = len(prompts.split(\"\\n\"))\n",
    "            prompt_lengths.append(prompt_length)\n",
    "\n",
    "            self.total_length += prompt_length\n",
    "\n",
    "        self.prompt_indexes = [0]\n",
    "        for i in prompt_lengths[:-1]:\n",
    "            self.prompt_indexes.append(self.prompt_indexes[-1] + i)\n",
    "\n",
    "        self.DSL = prompt\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        folder_idx = 0\n",
    "        for idx, val in enumerate(self.prompt_indexes):\n",
    "            if idx >= val:\n",
    "                folder_idx = idx\n",
    "\n",
    "        prompt_idx = idx - self.prompt_indexes[folder_idx]\n",
    "\n",
    "        code_dir = os.path.join(\n",
    "            self.data_dir, self.example_folders[folder_idx], \"code.txt\")\n",
    "        prompts_dir = os.path.join(\n",
    "            self.data_dir, self.example_folders[folder_idx], \"prompts.txt\")\n",
    "\n",
    "        with open(code_dir, 'r') as f:\n",
    "            code = f.read()\n",
    "\n",
    "        with open(prompts_dir, 'r') as f:\n",
    "            prompts = f.read().split(\"\\n\")\n",
    "\n",
    "        code = \"\\n\\t\".join(code.split(\"\\n\"))\n",
    "\n",
    "        final_prompt = self.DSL + prompts[prompt_idx] + \"\\n\\t\" + code\n",
    "        input_ids = self.tokenizer(\n",
    "            final_prompt, padding=\"max_length\", max_length=256)[\"input_ids\"]\n",
    "        return {\"input_ids\": input_ids, \"labels\": input_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"./checkpoints/checkpoint-300/\",\n",
    "        trust_remote_code=True\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"bigcode/santacoder\", use_auth_token=True)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DSL.txt\", 'r') as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "valid_dataset = CodeDataset(\"./test\", tokenizer, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def go_to(location : str)\n",
      "def find(object : str)\n",
      "def pick_up(object : str)\n",
      "def put_down(object : str)\n",
      "def find(object : str)\n",
      "def ask(person : str, question : str, options: Optional[List[str]])\n",
      "def say(message : str)\n",
      "'''\n",
      "def main():\n",
      "    # Using the functions defined above, write a script to do the following: Go to the kitchen. Then go to the living room. Repeat this 4 times.\n"
     ]
    }
   ],
   "source": [
    "with open(\"example_input.txt\", 'r') as f:\n",
    "    example_input = f.read()\n",
    "\n",
    "print(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(example_input, return_tensors=\"pt\", padding=\"max_length\", max_length=256).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "outputs = loaded_model.generate(inputs, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>def go_to(location : str)\n",
      "def find(object : str)\n",
      "def pick_up(object : str)\n",
      "def put_down(object : str)\n",
      "def find(object : str)\n",
      "def ask(person : str, question : str, options: Optional[List[str]])\n",
      "def say(message : str)\n",
      "'''\n",
      "def main():\n",
      "    # Using the functions defined above, write a script to do the following: Go to the kitchen. Then go to the living room. Repeat this 4 times.\n",
      "\tgo_to(\"Living room\")\n",
      "\tfind(\"TV Remote\")\n",
      "\tpick_up(\"TV Remote\")\n",
      "\tgo_to(\"Kitchen\")\n",
      "\tfind(\"Joydeep's office\")\n",
      "\tput_down(\"TV Remote\")\n",
      "\tgo_to(\"Yash's office\")\n",
      "\tput_down(\"apple\")\n",
      "\tgo_to(\"Yash's office\")\n",
      "\tput_down(\"apple\")\n",
      "\tgo_to(\"Yash's office\")\n",
      "\tput(\"apple\")\n",
      "\tgo_to(\"Yash(\"apple\")\n",
      "\tgo_to(\"Yash(\"\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot_commands",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
